{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test=pd.read_csv('data/test.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_len'] = train.text.map(lambda x : len(x))\n",
    "test['text_len'] = test.text.map(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  text_len  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1        69  \n",
       "1                Forest fire near La Ronge Sask. Canada       1        38  \n",
       "2     All residents asked to 'shelter in place' are ...       1       133  \n",
       "3     13,000 people receive #wildfires evacuation or...       1        65  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1        88  \n",
       "...                                                 ...     ...       ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1        83  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1       125  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1        65  \n",
       "7611  Police investigating after an e-bike collided ...       1       137  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1        94  \n",
       "\n",
       "[7613 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop('id',axis=1)\n",
    "test=test.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop('location',axis=1)\n",
    "test=test.drop('location',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ZAIDI Mohamed\n",
      "[nltk_data]     Arysse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus_train = []\n",
    "for i in range(0, len(train)):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', train['text'][i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  ps = PorterStemmer()\n",
    "  all_stopwords = stopwords.words('english')\n",
    "  all_stopwords.remove('not')\n",
    "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "  review = ' '.join(review)\n",
    "  corpus_train.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ZAIDI Mohamed\n",
      "[nltk_data]     Arysse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus_test = []\n",
    "for i in range(0, len(test)):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', test['text'][i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  ps = PorterStemmer()\n",
    "  all_stopwords = stopwords.words('english')\n",
    "  all_stopwords.remove('not')\n",
    "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "  review = ' '.join(review)\n",
    "  corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = corpus_train\n",
    "test['text'] = corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant crane hold bridg collaps nearbi home...</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>NaN</td>\n",
       "      <td>aria ahrari thetawniest control wild fire cali...</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>utc km volcano hawaii http co zdtoyd ebj</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>NaN</td>\n",
       "      <td>polic investig e bike collid car littl portug ...</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>NaN</td>\n",
       "      <td>latest home raze northern california wildfir a...</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword                                               text  target  \\\n",
       "0        NaN          deed reason earthquak may allah forgiv us       1   \n",
       "1        NaN               forest fire near la rong sask canada       1   \n",
       "2        NaN  resid ask shelter place notifi offic evacu she...       1   \n",
       "3        NaN        peopl receiv wildfir evacu order california       1   \n",
       "4        NaN  got sent photo rubi alaska smoke wildfir pour ...       1   \n",
       "...      ...                                                ...     ...   \n",
       "7608     NaN  two giant crane hold bridg collaps nearbi home...       1   \n",
       "7609     NaN  aria ahrari thetawniest control wild fire cali...       1   \n",
       "7610     NaN           utc km volcano hawaii http co zdtoyd ebj       1   \n",
       "7611     NaN  polic investig e bike collid car littl portug ...       1   \n",
       "7612     NaN  latest home raze northern california wildfir a...       1   \n",
       "\n",
       "      text_len  \n",
       "0           69  \n",
       "1           38  \n",
       "2          133  \n",
       "3           65  \n",
       "4           88  \n",
       "...        ...  \n",
       "7608        83  \n",
       "7609       125  \n",
       "7610        65  \n",
       "7611       137  \n",
       "7612        94  \n",
       "\n",
       "[7613 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train ['keyword'] = train['keyword'].fillna(value='fatalities')\n",
    "test ['keyword'] = test['keyword'].fillna(value='fatalities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL (text) :\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r\"\",text)\n",
    "\n",
    "def remove_HTML(text) :\n",
    "    html=re.compile(r\"<.*?>\")\n",
    "    return html.sub(r\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text\"] = train.text.map(lambda x: remove_URL(x))\n",
    "train[\"text\"] = train.text.map(lambda x: remove_HTML(x))\n",
    "train[\"text\"] = train.text.map(lambda x: remove_emoji(x))\n",
    "train[\"text\"] = train.text.map(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"text\"] = test.text.map(lambda x: remove_URL(x))\n",
    "test[\"text\"] = test.text.map(lambda x: remove_HTML(x))\n",
    "test[\"text\"] = test.text.map(lambda x: remove_emoji(x))\n",
    "test[\"text\"] = test.text.map(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>two giant crane hold bridg collaps nearbi home...</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>aria ahrari thetawniest control wild fire cali...</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>utc km volcano hawaii http co zdtoyd ebj</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>polic investig e bike collid car littl portug ...</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>latest home raze northern california wildfir a...</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         keyword                                               text  target  \\\n",
       "0     fatalities          deed reason earthquak may allah forgiv us       1   \n",
       "1     fatalities               forest fire near la rong sask canada       1   \n",
       "2     fatalities  resid ask shelter place notifi offic evacu she...       1   \n",
       "3     fatalities        peopl receiv wildfir evacu order california       1   \n",
       "4     fatalities  got sent photo rubi alaska smoke wildfir pour ...       1   \n",
       "...          ...                                                ...     ...   \n",
       "7608  fatalities  two giant crane hold bridg collaps nearbi home...       1   \n",
       "7609  fatalities  aria ahrari thetawniest control wild fire cali...       1   \n",
       "7610  fatalities           utc km volcano hawaii http co zdtoyd ebj       1   \n",
       "7611  fatalities  polic investig e bike collid car littl portug ...       1   \n",
       "7612  fatalities  latest home raze northern california wildfir a...       1   \n",
       "\n",
       "      text_len  \n",
       "0           69  \n",
       "1           38  \n",
       "2          133  \n",
       "3           65  \n",
       "4           88  \n",
       "...        ...  \n",
       "7608        83  \n",
       "7609       125  \n",
       "7610        65  \n",
       "7611       137  \n",
       "7612        94  \n",
       "\n",
       "[7613 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>happen terribl car crash</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>heard earthquak differ citi stay safe everyon</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>forest fire spot pond gees flee across street ...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>apocalyps light spokan wildfir</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>earthquak safeti lo angel safeti fasten xrwn</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>storm ri wors last hurrican citi amp other har...</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>green line derail chicago http co utbxlcbiuy</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>meg issu hazard weather outlook hwo http co x ...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>cityofcalgari activ municip emerg plan yycstorm</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         keyword                                               text  text_len\n",
       "0     fatalities                           happen terribl car crash        34\n",
       "1     fatalities      heard earthquak differ citi stay safe everyon        64\n",
       "2     fatalities  forest fire spot pond gees flee across street ...        96\n",
       "3     fatalities                     apocalyps light spokan wildfir        40\n",
       "4     fatalities                 typhoon soudelor kill china taiwan        45\n",
       "...          ...                                                ...       ...\n",
       "3258  fatalities       earthquak safeti lo angel safeti fasten xrwn        55\n",
       "3259  fatalities  storm ri wors last hurrican citi amp other har...       139\n",
       "3260  fatalities       green line derail chicago http co utbxlcbiuy        55\n",
       "3261  fatalities  meg issu hazard weather outlook hwo http co x ...        65\n",
       "3262  fatalities    cityofcalgari activ municip emerg plan yycstorm        68\n",
       "\n",
       "[3263 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def counter_word(text):\n",
    "    count = Counter()\n",
    "    for i in text.values:\n",
    "        for word in i.split():\n",
    "            count[word] += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train.text\n",
    "\n",
    "counter = counter_word(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18890"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(counter)\n",
    "max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(train.shape[0] * 0.8)\n",
    "\n",
    "train_sentences = train.text[:train_size]\n",
    "train_labels = train.target[:train_size]\n",
    "\n",
    "test_sentences = train.text[train_size:]\n",
    "test_labels = train.target[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "#associer à chaque mot un index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'co': 1,\n",
       " 'http': 2,\n",
       " 'like': 3,\n",
       " 'fire': 4,\n",
       " 'amp': 5,\n",
       " 'get': 6,\n",
       " 'not': 7,\n",
       " 'via': 8,\n",
       " 'new': 9,\n",
       " 'burn': 10,\n",
       " 'go': 11,\n",
       " 'peopl': 12,\n",
       " 'u': 13,\n",
       " 'news': 14,\n",
       " 'flood': 15,\n",
       " 'one': 16,\n",
       " 'emerg': 17,\n",
       " 'bomb': 18,\n",
       " 'w': 19,\n",
       " 'bodi': 20,\n",
       " 'year': 21,\n",
       " 'build': 22,\n",
       " 'crash': 23,\n",
       " 'time': 24,\n",
       " 'fatal': 25,\n",
       " 'video': 26,\n",
       " 'disast': 27,\n",
       " 'attack': 28,\n",
       " 'p': 29,\n",
       " 'evacu': 30,\n",
       " 'day': 31,\n",
       " 'x': 32,\n",
       " 'home': 33,\n",
       " 'kill': 34,\n",
       " 'love': 35,\n",
       " 'would': 36,\n",
       " 'say': 37,\n",
       " 'r': 38,\n",
       " 'bag': 39,\n",
       " 'derail': 40,\n",
       " 'collaps': 41,\n",
       " 'scream': 42,\n",
       " 'us': 43,\n",
       " 'death': 44,\n",
       " 'polic': 45,\n",
       " 'look': 46,\n",
       " 'famili': 47,\n",
       " 'c': 48,\n",
       " 'b': 49,\n",
       " 'see': 50,\n",
       " 'e': 51,\n",
       " 'know': 52,\n",
       " 'make': 53,\n",
       " 'drown': 54,\n",
       " 'come': 55,\n",
       " 'man': 56,\n",
       " 'want': 57,\n",
       " 'first': 58,\n",
       " 'n': 59,\n",
       " 'train': 60,\n",
       " 'watch': 61,\n",
       " 'california': 62,\n",
       " 'live': 63,\n",
       " 'world': 64,\n",
       " 'hijack': 65,\n",
       " 'accid': 66,\n",
       " 'back': 67,\n",
       " 'still': 68,\n",
       " 'got': 69,\n",
       " 'two': 70,\n",
       " 'work': 71,\n",
       " 'car': 72,\n",
       " 'obliter': 73,\n",
       " 'take': 74,\n",
       " 'destroy': 75,\n",
       " 'let': 76,\n",
       " 'full': 77,\n",
       " 'fear': 78,\n",
       " 'plan': 79,\n",
       " 'q': 80,\n",
       " 'injuri': 81,\n",
       " 'murder': 82,\n",
       " 'need': 83,\n",
       " 'l': 84,\n",
       " 'today': 85,\n",
       " 'nuclear': 86,\n",
       " 'rt': 87,\n",
       " 'gt': 88,\n",
       " 'think': 89,\n",
       " 'rescu': 90,\n",
       " 'g': 91,\n",
       " 'may': 92,\n",
       " 'youtub': 93,\n",
       " 'h': 94,\n",
       " 'servic': 95,\n",
       " 'riot': 96,\n",
       " 'hazard': 97,\n",
       " 'caus': 98,\n",
       " 'k': 99,\n",
       " 'mani': 100,\n",
       " 'v': 101,\n",
       " 'explod': 102,\n",
       " 'die': 103,\n",
       " 'mass': 104,\n",
       " 'dead': 105,\n",
       " 'z': 106,\n",
       " 'hostag': 107,\n",
       " 'hiroshima': 108,\n",
       " 'report': 109,\n",
       " 'collid': 110,\n",
       " 'quarantin': 111,\n",
       " 'wave': 112,\n",
       " 'way': 113,\n",
       " 'life': 114,\n",
       " 'use': 115,\n",
       " 'fuck': 116,\n",
       " 'crush': 117,\n",
       " 'last': 118,\n",
       " 'good': 119,\n",
       " 'feel': 120,\n",
       " 'j': 121,\n",
       " 'help': 122,\n",
       " 'even': 123,\n",
       " 'war': 124,\n",
       " 'damag': 125,\n",
       " 'best': 126,\n",
       " 'f': 127,\n",
       " 'devast': 128,\n",
       " 'read': 129,\n",
       " 'could': 130,\n",
       " 'catastroph': 131,\n",
       " 'casualti': 132,\n",
       " 'save': 133,\n",
       " 'deton': 134,\n",
       " 'forest': 135,\n",
       " 'hot': 136,\n",
       " 'delug': 137,\n",
       " 'electrocut': 138,\n",
       " 'run': 139,\n",
       " 'demolish': 140,\n",
       " 'black': 141,\n",
       " 'legionnair': 142,\n",
       " 'right': 143,\n",
       " 'hous': 144,\n",
       " 'flame': 145,\n",
       " 'bioterror': 146,\n",
       " 'reddit': 147,\n",
       " 'school': 148,\n",
       " 'thing': 149,\n",
       " 'fall': 150,\n",
       " 'desol': 151,\n",
       " 'set': 152,\n",
       " 'anoth': 153,\n",
       " 'cross': 154,\n",
       " 'stop': 155,\n",
       " 'storm': 156,\n",
       " 'injur': 157,\n",
       " 'realli': 158,\n",
       " 'citi': 159,\n",
       " 'thank': 160,\n",
       " 'pleas': 161,\n",
       " 'play': 162,\n",
       " 'annihil': 163,\n",
       " 'atom': 164,\n",
       " 'water': 165,\n",
       " 'tri': 166,\n",
       " 'blaze': 167,\n",
       " 'content': 168,\n",
       " 'call': 169,\n",
       " 'hit': 170,\n",
       " 'japan': 171,\n",
       " 'miss': 172,\n",
       " 'old': 173,\n",
       " 'wildfir': 174,\n",
       " 'photo': 175,\n",
       " 'everi': 176,\n",
       " 'truck': 177,\n",
       " 'pm': 178,\n",
       " 'latest': 179,\n",
       " 'women': 180,\n",
       " 'th': 181,\n",
       " 'oil': 182,\n",
       " 'face': 183,\n",
       " 'post': 184,\n",
       " 'area': 185,\n",
       " 'top': 186,\n",
       " 'end': 187,\n",
       " 'never': 188,\n",
       " 'natur': 189,\n",
       " 'armi': 190,\n",
       " 'lol': 191,\n",
       " 'pick': 192,\n",
       " 'near': 193,\n",
       " 'break': 194,\n",
       " 'much': 195,\n",
       " 'god': 196,\n",
       " 'debri': 197,\n",
       " 'offici': 198,\n",
       " 'charg': 199,\n",
       " 'wind': 200,\n",
       " 'refuge': 201,\n",
       " 'ass': 202,\n",
       " 'happen': 203,\n",
       " 'st': 204,\n",
       " 'im': 205,\n",
       " 'respond': 206,\n",
       " 'start': 207,\n",
       " 'hope': 208,\n",
       " 'militari': 209,\n",
       " 'northern': 210,\n",
       " 'danger': 211,\n",
       " 'updat': 212,\n",
       " 'rain': 213,\n",
       " 'night': 214,\n",
       " 'state': 215,\n",
       " 'explos': 216,\n",
       " 'food': 217,\n",
       " 'migrant': 218,\n",
       " 'heat': 219,\n",
       " 'check': 220,\n",
       " 'next': 221,\n",
       " 'everyon': 222,\n",
       " 'job': 223,\n",
       " 'littl': 224,\n",
       " 'boy': 225,\n",
       " 'hurrican': 226,\n",
       " 'ruin': 227,\n",
       " 'spill': 228,\n",
       " 'shit': 229,\n",
       " 'follow': 230,\n",
       " 'great': 231,\n",
       " 'game': 232,\n",
       " 'found': 233,\n",
       " 'sinc': 234,\n",
       " 'girl': 235,\n",
       " 'fan': 236,\n",
       " 'inund': 237,\n",
       " 'head': 238,\n",
       " 'bloodi': 239,\n",
       " 'blood': 240,\n",
       " 'show': 241,\n",
       " 'hail': 242,\n",
       " 'keep': 243,\n",
       " 'chang': 244,\n",
       " 'issu': 245,\n",
       " 'ever': 246,\n",
       " 'well': 247,\n",
       " 'light': 248,\n",
       " 'stori': 249,\n",
       " 'outbreak': 250,\n",
       " 'panic': 251,\n",
       " 'displac': 252,\n",
       " 'harm': 253,\n",
       " 'collis': 254,\n",
       " 'sinkhol': 255,\n",
       " 'alway': 256,\n",
       " 'guy': 257,\n",
       " 'air': 258,\n",
       " 'ambul': 259,\n",
       " 'said': 260,\n",
       " 'destruct': 261,\n",
       " 'land': 262,\n",
       " 'bridg': 263,\n",
       " 'road': 264,\n",
       " 'total': 265,\n",
       " 'battl': 266,\n",
       " 'market': 267,\n",
       " 'move': 268,\n",
       " 'free': 269,\n",
       " 'minut': 270,\n",
       " 'weather': 271,\n",
       " 'warn': 272,\n",
       " 'sound': 273,\n",
       " 'landslid': 274,\n",
       " 'loud': 275,\n",
       " 'gonna': 276,\n",
       " 'care': 277,\n",
       " 'nation': 278,\n",
       " 'high': 279,\n",
       " 'bad': 280,\n",
       " 'busi': 281,\n",
       " 'rescuer': 282,\n",
       " 'drought': 283,\n",
       " 'hundr': 284,\n",
       " 'order': 285,\n",
       " 'summer': 286,\n",
       " 'airplan': 287,\n",
       " 'sign': 288,\n",
       " 'armageddon': 289,\n",
       " 'real': 290,\n",
       " 'bleed': 291,\n",
       " 'lightn': 292,\n",
       " 'china': 293,\n",
       " 'curfew': 294,\n",
       " 'dust': 295,\n",
       " 'engulf': 296,\n",
       " 'famin': 297,\n",
       " 'massacr': 298,\n",
       " 'mudslid': 299,\n",
       " 'sandstorm': 300,\n",
       " 'close': 301,\n",
       " 'week': 302,\n",
       " 'made': 303,\n",
       " 'put': 304,\n",
       " 'babi': 305,\n",
       " 'chemic': 306,\n",
       " 'cliff': 307,\n",
       " 'mh': 308,\n",
       " 'bang': 309,\n",
       " 'earthquak': 310,\n",
       " 'bu': 311,\n",
       " 'also': 312,\n",
       " 'eye': 313,\n",
       " 'friend': 314,\n",
       " 'blast': 315,\n",
       " 'fedex': 316,\n",
       " 'send': 317,\n",
       " 'effect': 318,\n",
       " 'blown': 319,\n",
       " 'affect': 320,\n",
       " 'around': 321,\n",
       " 'leav': 322,\n",
       " 'tonight': 323,\n",
       " 'rd': 324,\n",
       " 'turn': 325,\n",
       " 'drive': 326,\n",
       " 'someon': 327,\n",
       " 'meltdown': 328,\n",
       " 'iran': 329,\n",
       " 'long': 330,\n",
       " 'link': 331,\n",
       " 'big': 332,\n",
       " 'deal': 333,\n",
       " 'power': 334,\n",
       " 'search': 335,\n",
       " 'rise': 336,\n",
       " 'flatten': 337,\n",
       " 'lava': 338,\n",
       " 'panick': 339,\n",
       " 'pandemonium': 340,\n",
       " 'raze': 341,\n",
       " 'kid': 342,\n",
       " 'island': 343,\n",
       " 'apocalyps': 344,\n",
       " 'red': 345,\n",
       " 'unit': 346,\n",
       " 'shoulder': 347,\n",
       " 'twitter': 348,\n",
       " 'obama': 349,\n",
       " 'blew': 350,\n",
       " 'anniversari': 351,\n",
       " 'boat': 352,\n",
       " 'demolit': 353,\n",
       " 'hellfir': 354,\n",
       " 'tell': 355,\n",
       " 'stand': 356,\n",
       " 'hour': 357,\n",
       " 'thought': 358,\n",
       " 'river': 359,\n",
       " 'self': 360,\n",
       " 'without': 361,\n",
       " 'white': 362,\n",
       " 'woman': 363,\n",
       " 'person': 364,\n",
       " 'intern': 365,\n",
       " 'rainstorm': 366,\n",
       " 'swallow': 367,\n",
       " 'wait': 368,\n",
       " 'past': 369,\n",
       " 'support': 370,\n",
       " 'possibl': 371,\n",
       " 'believ': 372,\n",
       " 'fight': 373,\n",
       " 'project': 374,\n",
       " 'away': 375,\n",
       " 'peac': 376,\n",
       " 'arson': 377,\n",
       " 'longer': 378,\n",
       " 'open': 379,\n",
       " 'cyclon': 380,\n",
       " 'eyewit': 381,\n",
       " 'cool': 382,\n",
       " 'heart': 383,\n",
       " 'left': 384,\n",
       " 'rememb': 385,\n",
       " 'came': 386,\n",
       " 'reunion': 387,\n",
       " 'govern': 388,\n",
       " 'phone': 389,\n",
       " 'lot': 390,\n",
       " 'went': 391,\n",
       " 'offens': 392,\n",
       " 'song': 393,\n",
       " 'lab': 394,\n",
       " 'ladi': 395,\n",
       " 'ur': 396,\n",
       " 'prebreak': 397,\n",
       " 'place': 398,\n",
       " 'ablaz': 399,\n",
       " 'better': 400,\n",
       " 'traffic': 401,\n",
       " 'heard': 402,\n",
       " 'shoot': 403,\n",
       " 'men': 404,\n",
       " 'ebay': 405,\n",
       " 'dog': 406,\n",
       " 'avalanch': 407,\n",
       " 'health': 408,\n",
       " 'ban': 409,\n",
       " 'due': 410,\n",
       " 'counti': 411,\n",
       " 'second': 412,\n",
       " 'least': 413,\n",
       " 'block': 414,\n",
       " 'horribl': 415,\n",
       " 'airport': 416,\n",
       " 'ship': 417,\n",
       " 'wake': 418,\n",
       " 'give': 419,\n",
       " 'tomorrow': 420,\n",
       " 'group': 421,\n",
       " 'blight': 422,\n",
       " 'polici': 423,\n",
       " 'half': 424,\n",
       " 'confirm': 425,\n",
       " 'stock': 426,\n",
       " 'sue': 427,\n",
       " 'reactor': 428,\n",
       " 'brown': 429,\n",
       " 'goe': 430,\n",
       " 'sure': 431,\n",
       " 'movi': 432,\n",
       " 'part': 433,\n",
       " 'calgari': 434,\n",
       " 'hold': 435,\n",
       " 'oh': 436,\n",
       " 'word': 437,\n",
       " 'line': 438,\n",
       " 'bush': 439,\n",
       " 'seismic': 440,\n",
       " 'far': 441,\n",
       " 'bring': 442,\n",
       " 'mean': 443,\n",
       " 'someth': 444,\n",
       " 'america': 445,\n",
       " 'vehicl': 446,\n",
       " 'plane': 447,\n",
       " 'walk': 448,\n",
       " 'case': 449,\n",
       " 'bc': 450,\n",
       " 'bar': 451,\n",
       " 'stay': 452,\n",
       " 'tweet': 453,\n",
       " 'music': 454,\n",
       " 'listen': 455,\n",
       " 'transport': 456,\n",
       " 'level': 457,\n",
       " 'investig': 458,\n",
       " 'nearbi': 459,\n",
       " 'sever': 460,\n",
       " 'memori': 461,\n",
       " 'ask': 462,\n",
       " 'street': 463,\n",
       " 'south': 464,\n",
       " 'flag': 465,\n",
       " 'shot': 466,\n",
       " 'talk': 467,\n",
       " 'final': 468,\n",
       " 'win': 469,\n",
       " 'actual': 470,\n",
       " 'lt': 471,\n",
       " 'must': 472,\n",
       " 'whole': 473,\n",
       " 'soon': 474,\n",
       " 'control': 475,\n",
       " 'american': 476,\n",
       " 'india': 477,\n",
       " 'media': 478,\n",
       " 'star': 479,\n",
       " 'ye': 480,\n",
       " 'wanna': 481,\n",
       " 'comput': 482,\n",
       " 'noth': 483,\n",
       " 'handbag': 484,\n",
       " 'mark': 485,\n",
       " 'rubbl': 486,\n",
       " 'offic': 487,\n",
       " 'book': 488,\n",
       " 'done': 489,\n",
       " 'suspect': 490,\n",
       " 'lead': 491,\n",
       " 'ok': 492,\n",
       " 'hate': 493,\n",
       " 'human': 494,\n",
       " 'share': 495,\n",
       " 'children': 496,\n",
       " 'learn': 497,\n",
       " 'yet': 498,\n",
       " 'team': 499,\n",
       " 'hear': 500,\n",
       " 'abc': 501,\n",
       " 'blizzard': 502,\n",
       " 'bigger': 503,\n",
       " 'villag': 504,\n",
       " 'knock': 505,\n",
       " 'hat': 506,\n",
       " 'reason': 507,\n",
       " 'la': 508,\n",
       " 'expect': 509,\n",
       " 'arsonist': 510,\n",
       " 'month': 511,\n",
       " 'aftershock': 512,\n",
       " 'alreadi': 513,\n",
       " 'begin': 514,\n",
       " 'aircraft': 515,\n",
       " 'ago': 516,\n",
       " 'name': 517,\n",
       " 'data': 518,\n",
       " 'tv': 519,\n",
       " 'amid': 520,\n",
       " 'anyth': 521,\n",
       " 'gun': 522,\n",
       " 'million': 523,\n",
       " 'yeah': 524,\n",
       " 'special': 525,\n",
       " 'rock': 526,\n",
       " 'find': 527,\n",
       " 'islam': 528,\n",
       " 'alarm': 529,\n",
       " 'manslaught': 530,\n",
       " 'three': 531,\n",
       " 'moment': 532,\n",
       " 'almost': 533,\n",
       " 'helicopt': 534,\n",
       " 'coupl': 535,\n",
       " 'park': 536,\n",
       " 'histori': 537,\n",
       " 'ball': 538,\n",
       " 'surviv': 539,\n",
       " 'august': 540,\n",
       " 'hand': 541,\n",
       " 'crisi': 542,\n",
       " 'beauti': 543,\n",
       " 'activ': 544,\n",
       " 'firefight': 545,\n",
       " 'cake': 546,\n",
       " 'pay': 547,\n",
       " 'morn': 548,\n",
       " 'probabl': 549,\n",
       " 'crew': 550,\n",
       " 'aug': 551,\n",
       " 'sensor': 552,\n",
       " 'declar': 553,\n",
       " 'insid': 554,\n",
       " 'north': 555,\n",
       " 'secret': 556,\n",
       " 'properti': 557,\n",
       " 'expert': 558,\n",
       " 'victim': 559,\n",
       " 'nigga': 560,\n",
       " 'fun': 561,\n",
       " 'point': 562,\n",
       " 'christian': 563,\n",
       " 'leather': 564,\n",
       " 'muslim': 565,\n",
       " 'youth': 566,\n",
       " 'liter': 567,\n",
       " 'interest': 568,\n",
       " 'camp': 569,\n",
       " 'angri': 570,\n",
       " 'ignit': 571,\n",
       " 'hailstorm': 572,\n",
       " 'mayhem': 573,\n",
       " 'refugio': 574,\n",
       " 'costlier': 575,\n",
       " 'side': 576,\n",
       " 'thousand': 577,\n",
       " 'center': 578,\n",
       " 'mom': 579,\n",
       " 'avoid': 580,\n",
       " 'hey': 581,\n",
       " 'everyth': 582,\n",
       " 'sorri': 583,\n",
       " 'countri': 584,\n",
       " 'hell': 585,\n",
       " 'major': 586,\n",
       " 'allow': 587,\n",
       " 'film': 588,\n",
       " 'prepar': 589,\n",
       " 'town': 590,\n",
       " 'isra': 591,\n",
       " 'releas': 592,\n",
       " 'act': 593,\n",
       " 'fukushima': 594,\n",
       " 'ad': 595,\n",
       " 'anthrax': 596,\n",
       " 'mishap': 597,\n",
       " 'gem': 598,\n",
       " 'appear': 599,\n",
       " 'russian': 600,\n",
       " 'giant': 601,\n",
       " 'cours': 602,\n",
       " 'imag': 603,\n",
       " 'km': 604,\n",
       " 'malaysia': 605,\n",
       " 'heavi': 606,\n",
       " 'lost': 607,\n",
       " 'myanmar': 608,\n",
       " 'wonder': 609,\n",
       " 'happi': 610,\n",
       " 'anyon': 611,\n",
       " 'cop': 612,\n",
       " 'worri': 613,\n",
       " 'complet': 614,\n",
       " 'usa': 615,\n",
       " 'mayb': 616,\n",
       " 'hors': 617,\n",
       " 'child': 618,\n",
       " 'action': 619,\n",
       " 'toddler': 620,\n",
       " 'saw': 621,\n",
       " 'blue': 622,\n",
       " 'sit': 623,\n",
       " 'forc': 624,\n",
       " 'ga': 625,\n",
       " 'gener': 626,\n",
       " 'space': 627,\n",
       " 'australia': 628,\n",
       " 'money': 629,\n",
       " 'wow': 630,\n",
       " 'strike': 631,\n",
       " 'fashion': 632,\n",
       " 'drake': 633,\n",
       " 'centr': 634,\n",
       " 'passeng': 635,\n",
       " 'disea': 636,\n",
       " 'spring': 637,\n",
       " 'arriv': 638,\n",
       " 'fast': 639,\n",
       " 'sky': 640,\n",
       " 'lord': 641,\n",
       " 'other': 642,\n",
       " 'public': 643,\n",
       " 'nowplay': 644,\n",
       " 'travel': 645,\n",
       " 'might': 646,\n",
       " 'omg': 647,\n",
       " 'number': 648,\n",
       " 'trust': 649,\n",
       " 'pile': 650,\n",
       " 'vs': 651,\n",
       " 'diseas': 652,\n",
       " 'yr': 653,\n",
       " 'escap': 654,\n",
       " 'class': 655,\n",
       " 'track': 656,\n",
       " 'vote': 657,\n",
       " 'date': 658,\n",
       " 'pray': 659,\n",
       " 'beach': 660,\n",
       " 'ca': 661,\n",
       " 'drink': 662,\n",
       " 'hire': 663,\n",
       " 'lie': 664,\n",
       " 'respons': 665,\n",
       " 'templ': 666,\n",
       " 'mount': 667,\n",
       " 'anim': 668,\n",
       " 'germ': 669,\n",
       " 'deliv': 670,\n",
       " 'nearli': 671,\n",
       " 'mad': 672,\n",
       " 'dont': 673,\n",
       " 'though': 674,\n",
       " 'low': 675,\n",
       " 'meek': 676,\n",
       " 'spot': 677,\n",
       " 'gbbo': 678,\n",
       " 'downtown': 679,\n",
       " 'becom': 680,\n",
       " 'continu': 681,\n",
       " 'compani': 682,\n",
       " 'tree': 683,\n",
       " 'smoke': 684,\n",
       " 'flash': 685,\n",
       " 'cri': 686,\n",
       " 'outsid': 687,\n",
       " 'chicago': 688,\n",
       " 'hard': 689,\n",
       " 'front': 690,\n",
       " 'els': 691,\n",
       " 'involv': 692,\n",
       " 'pain': 693,\n",
       " 'daili': 694,\n",
       " 'franc': 695,\n",
       " 'polit': 696,\n",
       " 'em': 697,\n",
       " 'mine': 698,\n",
       " 'east': 699,\n",
       " 'arrest': 700,\n",
       " 'remov': 701,\n",
       " 'green': 702,\n",
       " 'theater': 703,\n",
       " 'civilian': 704,\n",
       " 'cover': 705,\n",
       " 'commun': 706,\n",
       " 'sea': 707,\n",
       " 'taken': 708,\n",
       " 'pic': 709,\n",
       " 'wed': 710,\n",
       " 'dude': 711,\n",
       " 'info': 712,\n",
       " 'result': 713,\n",
       " 'tote': 714,\n",
       " 'guid': 715,\n",
       " 'outrag': 716,\n",
       " 'insur': 717,\n",
       " 'mph': 718,\n",
       " 'chanc': 719,\n",
       " 'thunderstorm': 720,\n",
       " 'uk': 721,\n",
       " 'typhoon': 722,\n",
       " 'former': 723,\n",
       " 'madhya': 724,\n",
       " 'pradesh': 725,\n",
       " 'led': 726,\n",
       " 'lamp': 727,\n",
       " 'bayelsa': 728,\n",
       " 'funtenna': 729,\n",
       " 'subreddit': 730,\n",
       " 'across': 731,\n",
       " 'site': 732,\n",
       " 'grow': 733,\n",
       " 'west': 734,\n",
       " 'climat': 735,\n",
       " 'student': 736,\n",
       " 'huge': 737,\n",
       " 'scene': 738,\n",
       " 'pass': 739,\n",
       " 'entir': 740,\n",
       " 'israel': 741,\n",
       " 'seen': 742,\n",
       " 'match': 743,\n",
       " 'mention': 744,\n",
       " 'question': 745,\n",
       " 'scare': 746,\n",
       " 'extrem': 747,\n",
       " 'till': 748,\n",
       " 'russia': 749,\n",
       " 'caught': 750,\n",
       " 'terror': 751,\n",
       " 'claim': 752,\n",
       " 'milit': 753,\n",
       " 'damn': 754,\n",
       " 'pamela': 755,\n",
       " 'worst': 756,\n",
       " 'nd': 757,\n",
       " 'carri': 758,\n",
       " 'bless': 759,\n",
       " 'buy': 760,\n",
       " 'standard': 761,\n",
       " 'larg': 762,\n",
       " 'mind': 763,\n",
       " 'record': 764,\n",
       " 'mp': 765,\n",
       " 'differ': 766,\n",
       " 'patienc': 767,\n",
       " 'nigerian': 768,\n",
       " 'parol': 769,\n",
       " 'unconfirm': 770,\n",
       " 'neighbour': 771,\n",
       " 'direct': 772,\n",
       " 'colorado': 773,\n",
       " 'haha': 774,\n",
       " 'aba': 775,\n",
       " 'awesom': 776,\n",
       " 'ave': 777,\n",
       " 'dr': 778,\n",
       " 'ice': 779,\n",
       " 'wrong': 780,\n",
       " 'kick': 781,\n",
       " 'wednesday': 782,\n",
       " 'id': 783,\n",
       " 'pakistani': 784,\n",
       " 'target': 785,\n",
       " 'driver': 786,\n",
       " 'review': 787,\n",
       " 'potu': 788,\n",
       " 'soul': 789,\n",
       " 'poor': 790,\n",
       " 'queen': 791,\n",
       " 'beat': 792,\n",
       " 'hero': 793,\n",
       " 'struggl': 794,\n",
       " 'true': 795,\n",
       " 'shift': 796,\n",
       " 'geller': 797,\n",
       " 'answer': 798,\n",
       " 'cut': 799,\n",
       " 'concern': 800,\n",
       " 'ebola': 801,\n",
       " 'parti': 802,\n",
       " 'silver': 803,\n",
       " 'onlin': 804,\n",
       " 'ash': 805,\n",
       " 'enough': 806,\n",
       " 'bitch': 807,\n",
       " 'ground': 808,\n",
       " 'art': 809,\n",
       " 'idea': 810,\n",
       " 'middl': 811,\n",
       " 'thursday': 812,\n",
       " 'libya': 813,\n",
       " 'desir': 814,\n",
       " 'press': 815,\n",
       " 'ppl': 816,\n",
       " 'govt': 817,\n",
       " 'account': 818,\n",
       " 'rate': 819,\n",
       " 'isi': 820,\n",
       " 'emmerdal': 821,\n",
       " 'york': 822,\n",
       " 'quiz': 823,\n",
       " 'apollo': 824,\n",
       " 'utc': 825,\n",
       " 'cree': 826,\n",
       " 'sick': 827,\n",
       " 'crematoria': 828,\n",
       " 'provok': 829,\n",
       " 'london': 830,\n",
       " 'owner': 831,\n",
       " 'behind': 832,\n",
       " 'lose': 833,\n",
       " 'member': 834,\n",
       " 'hospit': 835,\n",
       " 'twelv': 836,\n",
       " 'incid': 837,\n",
       " 'crazi': 838,\n",
       " 'pakistan': 839,\n",
       " 'ny': 840,\n",
       " 'petit': 841,\n",
       " 'meet': 842,\n",
       " 'career': 843,\n",
       " 'un': 844,\n",
       " 'safeti': 845,\n",
       " 'readi': 846,\n",
       " 'survivor': 847,\n",
       " 'wild': 848,\n",
       " 'radio': 849,\n",
       " 'mountain': 850,\n",
       " 'door': 851,\n",
       " 'depart': 852,\n",
       " 'earth': 853,\n",
       " 'sport': 854,\n",
       " 'japanes': 855,\n",
       " 'gop': 856,\n",
       " 'king': 857,\n",
       " 'favorit': 858,\n",
       " 'occur': 859,\n",
       " 'young': 860,\n",
       " 'problem': 861,\n",
       " 'secur': 862,\n",
       " 'pretti': 863,\n",
       " 'list': 864,\n",
       " 'ahead': 865,\n",
       " 'event': 866,\n",
       " 'coast': 867,\n",
       " 'told': 868,\n",
       " 'estim': 869,\n",
       " 'wall': 870,\n",
       " 'sad': 871,\n",
       " 'aw': 872,\n",
       " 'drop': 873,\n",
       " 'social': 874,\n",
       " 'parent': 875,\n",
       " 'manag': 876,\n",
       " 'absolut': 877,\n",
       " 'cost': 878,\n",
       " 'nurs': 879,\n",
       " 'jonathan': 880,\n",
       " 'governor': 881,\n",
       " 'season': 882,\n",
       " 'singl': 883,\n",
       " 'later': 884,\n",
       " 'angel': 885,\n",
       " 'michael': 886,\n",
       " 'mile': 887,\n",
       " 'doubl': 888,\n",
       " 'risk': 889,\n",
       " 'gm': 890,\n",
       " 'financi': 891,\n",
       " 'global': 892,\n",
       " 'bb': 893,\n",
       " 'rip': 894,\n",
       " 'ap': 895,\n",
       " 'pull': 896,\n",
       " 'sw': 897,\n",
       " 'mod': 898,\n",
       " 'dad': 899,\n",
       " 'enjoy': 900,\n",
       " 'bed': 901,\n",
       " 'base': 902,\n",
       " 'fail': 903,\n",
       " 'local': 904,\n",
       " 'lmao': 905,\n",
       " 'weapon': 906,\n",
       " 'user': 907,\n",
       " 'okay': 908,\n",
       " 'loui': 909,\n",
       " 'album': 910,\n",
       " 'pc': 911,\n",
       " 'research': 912,\n",
       " 'ft': 913,\n",
       " 'loss': 914,\n",
       " 'write': 915,\n",
       " 'cold': 916,\n",
       " 'text': 917,\n",
       " 'matter': 918,\n",
       " 'broke': 919,\n",
       " 'killer': 920,\n",
       " 'faux': 921,\n",
       " 'room': 922,\n",
       " 'nagasaki': 923,\n",
       " 'crane': 924,\n",
       " 'threaten': 925,\n",
       " 'western': 926,\n",
       " 'blow': 927,\n",
       " 'remain': 928,\n",
       " 'return': 929,\n",
       " 'shape': 930,\n",
       " 'reduc': 931,\n",
       " 'oper': 932,\n",
       " 'bbc': 933,\n",
       " 'replac': 934,\n",
       " 'instead': 935,\n",
       " 'cabl': 936,\n",
       " 'enugu': 937,\n",
       " 'wrought': 938,\n",
       " 'brooklyn': 939,\n",
       " 'offroad': 940,\n",
       " 'apc': 941,\n",
       " 'lake': 942,\n",
       " 'metal': 943,\n",
       " 'alon': 944,\n",
       " 'wife': 945,\n",
       " 'upon': 946,\n",
       " 'usual': 947,\n",
       " 'wish': 948,\n",
       " 'leader': 949,\n",
       " 'comment': 950,\n",
       " 'danc': 951,\n",
       " 'guess': 952,\n",
       " 'protect': 953,\n",
       " 'mode': 954,\n",
       " 'seriou': 955,\n",
       " 'reuter': 956,\n",
       " 'horror': 957,\n",
       " 'pre': 958,\n",
       " 'salt': 959,\n",
       " 'fuel': 960,\n",
       " 'join': 961,\n",
       " 'stage': 962,\n",
       " 'took': 963,\n",
       " 'dark': 964,\n",
       " 'seri': 965,\n",
       " 'indian': 966,\n",
       " 'ya': 967,\n",
       " 'crime': 968,\n",
       " 'palestinian': 969,\n",
       " 'blame': 970,\n",
       " 'cant': 971,\n",
       " 'gave': 972,\n",
       " 'internet': 973,\n",
       " 'so': 974,\n",
       " 'fat': 975,\n",
       " 'prevent': 976,\n",
       " 'lift': 977,\n",
       " 'yo': 978,\n",
       " 'usatoday': 979,\n",
       " 'pathogen': 980,\n",
       " 'potenti': 981,\n",
       " 'region': 982,\n",
       " 'wire': 983,\n",
       " 'futur': 984,\n",
       " 'technolog': 985,\n",
       " 'test': 986,\n",
       " 'agre': 987,\n",
       " 'tear': 988,\n",
       " 'glass': 989,\n",
       " 'feet': 990,\n",
       " 'articl': 991,\n",
       " 'metro': 992,\n",
       " 'biggest': 993,\n",
       " 'sink': 994,\n",
       " 'friday': 995,\n",
       " 'purs': 996,\n",
       " 'small': 997,\n",
       " 'washington': 998,\n",
       " 'gunman': 999,\n",
       " 'di': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "train_padded = pad_sequences(\n",
    "    train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "#Car pour que LSTM marche, il faut qu'on ait des séquences de même longueur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3512, 507, 310, 92, 1289, 2749, 43]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3512,  507,  310,   92, 1289, 2749,   43,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(\n",
    "    test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.initializers import Constant\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(num_words, 32, input_length=max_length))\n",
    "model.add(LSTM(64, dropout=0.1))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',mode='min',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 [==============================] - 7s 18ms/step - loss: 0.5286 - val_loss: 0.4366\n",
      "Epoch 2/20\n",
      "191/191 [==============================] - 3s 15ms/step - loss: 0.3006 - val_loss: 0.5245\n",
      "Epoch 3/20\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.1641 - val_loss: 0.6289\n",
      "Epoch 4/20\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.0940 - val_loss: 0.9298\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_padded, train_labels, epochs=20, validation_data=(test_padded, test_labels),callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04a834920b7def6fd20c473cd69d4248d5cd7791bb116f54149a6750c1f73918"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
